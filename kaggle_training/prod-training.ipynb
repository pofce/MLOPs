{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30733,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": "!pip install mlflow\n!pip install azure-storage-blob",
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2024-06-08T09:40:00.188790Z",
     "iopub.execute_input": "2024-06-08T09:40:00.189087Z",
     "iopub.status.idle": "2024-06-08T09:40:34.556388Z",
     "shell.execute_reply.started": "2024-06-08T09:40:00.189063Z",
     "shell.execute_reply": "2024-06-08T09:40:34.555259Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "text": "Collecting mlflow\n  Downloading mlflow-2.13.2-py3-none-any.whl.metadata (29 kB)\nRequirement already satisfied: Flask<4 in /opt/conda/lib/python3.10/site-packages (from mlflow) (3.0.3)\nRequirement already satisfied: alembic!=1.10.0,<2 in /opt/conda/lib/python3.10/site-packages (from mlflow) (1.13.1)\nCollecting cachetools<6,>=5.0.0 (from mlflow)\n  Downloading cachetools-5.3.3-py3-none-any.whl.metadata (5.3 kB)\nRequirement already satisfied: click<9,>=7.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (8.1.7)\nRequirement already satisfied: cloudpickle<4 in /opt/conda/lib/python3.10/site-packages (from mlflow) (2.2.1)\nRequirement already satisfied: docker<8,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (7.0.0)\nRequirement already satisfied: entrypoints<1 in /opt/conda/lib/python3.10/site-packages (from mlflow) (0.4)\nRequirement already satisfied: gitpython<4,>=3.1.9 in /opt/conda/lib/python3.10/site-packages (from mlflow) (3.1.41)\nCollecting graphene<4 (from mlflow)\n  Downloading graphene-3.3-py2.py3-none-any.whl.metadata (7.7 kB)\nRequirement already satisfied: importlib-metadata!=4.7.0,<8,>=3.7.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (6.11.0)\nRequirement already satisfied: markdown<4,>=3.3 in /opt/conda/lib/python3.10/site-packages (from mlflow) (3.5.2)\nRequirement already satisfied: matplotlib<4 in /opt/conda/lib/python3.10/site-packages (from mlflow) (3.7.5)\nRequirement already satisfied: numpy<2 in /opt/conda/lib/python3.10/site-packages (from mlflow) (1.26.4)\nRequirement already satisfied: opentelemetry-api<3,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (1.22.0)\nRequirement already satisfied: opentelemetry-sdk<3,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (1.22.0)\nRequirement already satisfied: packaging<25 in /opt/conda/lib/python3.10/site-packages (from mlflow) (21.3)\nRequirement already satisfied: pandas<3 in /opt/conda/lib/python3.10/site-packages (from mlflow) (2.2.1)\nRequirement already satisfied: protobuf<5,>=3.12.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (3.20.3)\nRequirement already satisfied: pyarrow<16,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (14.0.2)\nRequirement already satisfied: pytz<2025 in /opt/conda/lib/python3.10/site-packages (from mlflow) (2023.3.post1)\nRequirement already satisfied: pyyaml<7,>=5.1 in /opt/conda/lib/python3.10/site-packages (from mlflow) (6.0.1)\nCollecting querystring-parser<2 (from mlflow)\n  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl.metadata (559 bytes)\nRequirement already satisfied: requests<3,>=2.17.3 in /opt/conda/lib/python3.10/site-packages (from mlflow) (2.32.3)\nRequirement already satisfied: scikit-learn<2 in /opt/conda/lib/python3.10/site-packages (from mlflow) (1.2.2)\nRequirement already satisfied: scipy<2 in /opt/conda/lib/python3.10/site-packages (from mlflow) (1.11.4)\nRequirement already satisfied: sqlalchemy<3,>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (2.0.25)\nRequirement already satisfied: sqlparse<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (0.4.4)\nRequirement already satisfied: Jinja2<4,>=2.11 in /opt/conda/lib/python3.10/site-packages (from mlflow) (3.1.2)\nCollecting gunicorn<23 (from mlflow)\n  Downloading gunicorn-22.0.0-py3-none-any.whl.metadata (4.4 kB)\nRequirement already satisfied: Mako in /opt/conda/lib/python3.10/site-packages (from alembic!=1.10.0,<2->mlflow) (1.3.5)\nRequirement already satisfied: typing-extensions>=4 in /opt/conda/lib/python3.10/site-packages (from alembic!=1.10.0,<2->mlflow) (4.9.0)\nRequirement already satisfied: urllib3>=1.26.0 in /opt/conda/lib/python3.10/site-packages (from docker<8,>=4.0.0->mlflow) (1.26.18)\nRequirement already satisfied: Werkzeug>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from Flask<4->mlflow) (3.0.3)\nRequirement already satisfied: itsdangerous>=2.1.2 in /opt/conda/lib/python3.10/site-packages (from Flask<4->mlflow) (2.2.0)\nRequirement already satisfied: blinker>=1.6.2 in /opt/conda/lib/python3.10/site-packages (from Flask<4->mlflow) (1.8.2)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython<4,>=3.1.9->mlflow) (4.0.11)\nCollecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n  Downloading graphql_core-3.2.3-py3-none-any.whl.metadata (10 kB)\nCollecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\nCollecting aniso8601<10,>=8 (from graphene<4->mlflow)\n  Downloading aniso8601-9.0.1-py2.py3-none-any.whl.metadata (23 kB)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata!=4.7.0,<8,>=3.7.0->mlflow) (3.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from Jinja2<4,>=2.11->mlflow) (2.1.3)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow) (1.4.5)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow) (9.5.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow) (2.9.0.post0)\nRequirement already satisfied: deprecated>=1.2.6 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-api<3,>=1.0.0->mlflow) (1.2.14)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.43b0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-sdk<3,>=1.0.0->mlflow) (0.43b0)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas<3->mlflow) (2023.4)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from querystring-parser<2->mlflow) (1.16.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow) (3.6)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow) (2024.2.2)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn<2->mlflow) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn<2->mlflow) (3.2.0)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.0.3)\nRequirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.10/site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.0.0->mlflow) (1.14.1)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow) (5.0.1)\nDownloading mlflow-2.13.2-py3-none-any.whl (25.0 MB)\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m25.0/25.0 MB\u001B[0m \u001B[31m48.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0mm\n\u001B[?25hDownloading cachetools-5.3.3-py3-none-any.whl (9.3 kB)\nDownloading graphene-3.3-py2.py3-none-any.whl (128 kB)\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m128.2/128.2 kB\u001B[0m \u001B[31m8.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading gunicorn-22.0.0-py3-none-any.whl (84 kB)\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m84.4/84.4 kB\u001B[0m \u001B[31m4.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\nDownloading aniso8601-9.0.1-py2.py3-none-any.whl (52 kB)\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m52.8/52.8 kB\u001B[0m \u001B[31m2.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading graphql_core-3.2.3-py3-none-any.whl (202 kB)\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m202.9/202.9 kB\u001B[0m \u001B[31m13.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\nInstalling collected packages: aniso8601, querystring-parser, graphql-core, cachetools, gunicorn, graphql-relay, graphene, mlflow\n  Attempting uninstall: cachetools\n    Found existing installation: cachetools 4.2.4\n    Uninstalling cachetools-4.2.4:\n      Successfully uninstalled cachetools-4.2.4\n\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 24.4.1 requires cubinlinker, which is not installed.\ncudf 24.4.1 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 24.4.1 requires ptxcompiler, which is not installed.\ncuml 24.4.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 24.4.1 requires cupy-cuda11x>=12.0.0, which is not installed.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\ncudf 24.4.1 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.5.0 which is incompatible.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.3.3 which is incompatible.\u001B[0m\u001B[31m\n\u001B[0mSuccessfully installed aniso8601-9.0.1 cachetools-5.3.2 graphene-3.3 graphql-core-3.2.3 graphql-relay-3.2.0 gunicorn-22.0.0 mlflow-2.13.2 querystring-parser-1.2.4\nCollecting azure-storage-blob\n  Downloading azure_storage_blob-12.20.0-py3-none-any.whl.metadata (26 kB)\nCollecting azure-core>=1.28.0 (from azure-storage-blob)\n  Downloading azure_core-1.30.2-py3-none-any.whl.metadata (37 kB)\nRequirement already satisfied: cryptography>=2.1.4 in /opt/conda/lib/python3.10/site-packages (from azure-storage-blob) (41.0.7)\nRequirement already satisfied: typing-extensions>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from azure-storage-blob) (4.9.0)\nCollecting isodate>=0.6.1 (from azure-storage-blob)\n  Downloading isodate-0.6.1-py2.py3-none-any.whl.metadata (9.6 kB)\nRequirement already satisfied: requests>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from azure-core>=1.28.0->azure-storage-blob) (2.32.3)\nRequirement already satisfied: six>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from azure-core>=1.28.0->azure-storage-blob) (1.16.0)\nRequirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography>=2.1.4->azure-storage-blob) (1.16.0)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob) (2.21)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.28.0->azure-storage-blob) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.28.0->azure-storage-blob) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.28.0->azure-storage-blob) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.28.0->azure-storage-blob) (2024.2.2)\nDownloading azure_storage_blob-12.20.0-py3-none-any.whl (392 kB)\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m392.2/392.2 kB\u001B[0m \u001B[31m3.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n\u001B[?25hDownloading azure_core-1.30.2-py3-none-any.whl (194 kB)\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m194.3/194.3 kB\u001B[0m \u001B[31m11.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m41.7/41.7 kB\u001B[0m \u001B[31m2.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hInstalling collected packages: isodate, azure-core, azure-storage-blob\nSuccessfully installed azure-core-1.30.2 azure-storage-blob-12.20.0 isodate-0.6.1\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "%%sh\n",
    "\n",
    "# Define the configuration file path\n",
    "config_file=\"$HOME/.databrickscfg\"\n",
    "\n",
    "# Create the configuration file with user input\n",
    "echo \"[DEFAULT]\" > \"$config_file\"\n",
    "echo \"host = https://community.cloud.databricks.com/\" >> \"$config_file\"\n",
    "echo \"username = ...\" >> \"$config_file\"\n",
    "echo \"password = ...\" >> \"$config_file\"\n",
    "echo \"jobs-api-version = 2.0\" >> \"$config_file\"\n",
    "\n",
    "# Set the file permissions to read and write for the user only\n",
    "chmod 600 \"$config_file\"\n",
    "\n",
    "echo \"Configuration file created at $config_file\"\n",
    "\n",
    "cat /root/.databrickscfg"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-08T09:40:34.558525Z",
     "iopub.execute_input": "2024-06-08T09:40:34.558841Z",
     "iopub.status.idle": "2024-06-08T09:40:34.588365Z",
     "shell.execute_reply.started": "2024-06-08T09:40:34.558814Z",
     "shell.execute_reply": "2024-06-08T09:40:34.587510Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": "Configuration file created at /root/.databrickscfg\n[DEFAULT]\nhost = https://community.cloud.databricks.com/\nusername = vladyslav.radchenko@outlook.com\npassword = Dkfldkfl007!\njobs-api-version = 2.0\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "import io\n",
    "\n",
    "account_url = \"...\"\n",
    "sas_token = \"...\"\n",
    "container_name = \"...\"\n",
    "\n",
    "# Create a BlobServiceClient\n",
    "blob_service_client = BlobServiceClient(account_url=account_url, credential=sas_token)\n",
    "container_client = blob_service_client.get_container_client(container_name)\n",
    "\n",
    "def read_csv_from_blob(file_name):\n",
    "    \"\"\"\n",
    "    Download and read a CSV file from Azure Blob Storage into a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    blob_client = container_client.get_blob_client(blob=file_name)\n",
    "    try:\n",
    "        # Download the blob data\n",
    "        blob_data = blob_client.download_blob()\n",
    "        # Load the data into a DataFrame\n",
    "        data_frame = pd.read_csv(io.BytesIO(blob_data.readall()))\n",
    "        return data_frame\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download or parse {file_name}: {e}\")\n",
    "        return None"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-08T09:40:37.507728Z",
     "iopub.execute_input": "2024-06-08T09:40:37.508194Z",
     "iopub.status.idle": "2024-06-08T09:40:37.964797Z",
     "shell.execute_reply.started": "2024-06-08T09:40:37.508167Z",
     "shell.execute_reply": "2024-06-08T09:40:37.963968Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# read_csv_from_blob(\"Twitter_Data.csv\"), read_csv_from_blob(\"Reddit_Data.csv\")\n\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom transformers import RobertaTokenizer, RobertaForSequenceClassification\nfrom torch.utils.data import DataLoader, TensorDataset\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport warnings\nwarnings.filterwarnings('ignore')",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-08T09:40:37.967092Z",
     "iopub.execute_input": "2024-06-08T09:40:37.967621Z",
     "iopub.status.idle": "2024-06-08T09:40:44.911567Z",
     "shell.execute_reply.started": "2024-06-08T09:40:37.967592Z",
     "shell.execute_reply": "2024-06-08T09:40:44.910649Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "data = read_csv_from_blob(\"Twitter_Data.csv\")\n",
    "\n",
    "data.dropna(inplace=True)\n",
    "data.drop_duplicates(subset=['clean_text'], inplace=True)\n",
    "\n",
    "texts = data['clean_text'].values\n",
    "labels = data['category'].values  \n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels_train = label_encoder.fit_transform(train_labels)\n",
    "label_mapping = {original_label: int_label for original_label, int_label in zip(train_labels, encoded_labels_train)}\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels_valid = label_encoder.fit_transform(val_labels)\n",
    "label_mapping = {original_label: int_label for original_label, int_label in zip(val_labels, encoded_labels_valid)}"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-08T09:40:44.912795Z",
     "iopub.execute_input": "2024-06-08T09:40:44.913580Z",
     "iopub.status.idle": "2024-06-08T09:40:46.454748Z",
     "shell.execute_reply.started": "2024-06-08T09:40:44.913546Z",
     "shell.execute_reply": "2024-06-08T09:40:46.453885Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\nmodel = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=3)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-08T09:40:46.455914Z",
     "iopub.execute_input": "2024-06-08T09:40:46.456208Z",
     "iopub.status.idle": "2024-06-08T09:40:50.780079Z",
     "shell.execute_reply.started": "2024-06-08T09:40:46.456183Z",
     "shell.execute_reply": "2024-06-08T09:40:50.779030Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "71829c71e1f84f67808473835501ed1d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7b0a611f53344eba8f91cf183a4b9792"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1cb8216f42fa476c8e0732a9685cd97d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e98164c500594737a04809e044958693"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4040484c6117442aa6a34d65db6afe78"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ad9e6e3b94634f7f99a69c4a77ff63c5"
      }
     },
     "metadata": {}
    },
    {
     "name": "stderr",
     "text": "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "from torch.utils.data import Dataset, DataLoader\n\nclass Sentiment(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_len=128):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = str(self.texts[idx])\n        label = self.labels[idx]\n        \n        encoding = self.tokenizer.encode_plus(\n            text,\n            truncation=True,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            return_token_type_ids=False,\n            pad_to_max_length=True,\n            return_attention_mask=True,\n            return_tensors='pt',\n        )\n        \n        return {\n            'text': text,\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'labels': torch.tensor(label, dtype=torch.long)\n        }\n\ntrain_labels = encoded_labels_train\nval_labels = encoded_labels_valid\n\ntrain_data = Sentiment(train_texts, train_labels, tokenizer, max_len=128)\nval_data = Sentiment(val_texts, val_labels, tokenizer, max_len=128)\n\ntrain_loader = DataLoader(train_data, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_data, batch_size=32)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-08T09:40:50.781768Z",
     "iopub.execute_input": "2024-06-08T09:40:50.782208Z",
     "iopub.status.idle": "2024-06-08T09:40:50.794004Z",
     "shell.execute_reply.started": "2024-06-08T09:40:50.782170Z",
     "shell.execute_reply": "2024-06-08T09:40:50.792781Z"
    },
    "trusted": true
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def get_test_scores():\n",
    "    reddit = read_csv_from_blob(\"Reddit_Data.csv\")\n",
    "    reddit.rename(columns={'clean_comment': 'clean_text'}, inplace=True)\n",
    "\n",
    "    reddit.dropna(inplace=True)\n",
    "\n",
    "    reddit.drop_duplicates(subset=['clean_text'], inplace=True)\n",
    "\n",
    "    reddit.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    from torch.utils.data import DataLoader\n",
    "\n",
    "    test_enc_labels = label_encoder.transform(reddit['category'])\n",
    "    test_dataset = Sentiment(reddit['clean_text'], test_enc_labels, tokenizer, max_len=128)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    all_predictions = []\n",
    "    all_true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            predictions = torch.argmax(outputs.logits, dim=1)\n",
    "\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    predicted_labels = label_encoder.inverse_transform(all_predictions)\n",
    "    true_labels = label_encoder.inverse_transform(all_true_labels)\n",
    "    \n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    report_dict = classification_report(true_labels, predicted_labels, output_dict=True)\n",
    "\n",
    "    return accuracy, report_dict"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-08T09:40:50.795346Z",
     "iopub.execute_input": "2024-06-08T09:40:50.795642Z",
     "iopub.status.idle": "2024-06-08T09:40:51.165411Z",
     "shell.execute_reply.started": "2024-06-08T09:40:50.795617Z",
     "shell.execute_reply": "2024-06-08T09:40:51.164345Z"
    },
    "trusted": true
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "import mlflow\n\nmlflow.set_tracking_uri(\"databricks\")\nmlflow.set_experiment(\"/Users/vladyslav.radchenko@outlook.com/MLOPs Tracking\")\n#S5gbYBc=RQJ8@n8\n\n\nfrom transformers import AdamW\n\n\nwith mlflow.start_run(run_name=\"MLOPs Tracking\"):\n    mlflow.log_param(\"learning_rate\", 1e-5)\n    optimizer = AdamW(model.parameters(), lr=1e-5)\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n\n    for epoch in range(1):\n        model.train()\n        for batch in train_loader:\n            optimizer.zero_grad()\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n            loss = outputs[0]\n            loss.backward()\n            optimizer.step()\n\n        # Validation loop\n        model.eval()\n        val_loss = 0\n        val_accuracy = 0\n        with torch.no_grad():\n            for batch in val_loader:\n                input_ids = batch['input_ids'].to(device)\n                attention_mask = batch['attention_mask'].to(device)\n                labels = batch['labels'].to(device)\n                outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n                loss = outputs[0]\n                val_loss += loss.item()\n\n                logits = outputs.logits\n                predictions = torch.argmax(logits, dim=1)\n                accuracy = accuracy_score(labels.cpu(), predictions.cpu())\n                val_accuracy += accuracy\n\n        val_loss /= len(val_loader)\n        val_accuracy /= len(val_loader)\n\n    mlflow.pytorch.log_model(model, \"model\")\n\n    accuracy, report_dict = get_test_scores()\n    mlflow.log_metric(\"accuracy\", accuracy)\n    mlflow.log_metric(\"macro_avg_precision\", report_dict[\"macro avg\"][\"precision\"])\n    mlflow.log_metric(\"macro_avg_recall\", report_dict[\"macro avg\"][\"recall\"])\n    mlflow.log_metric(\"macro_avg_f1-score\", report_dict[\"macro avg\"][\"f1-score\"])",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-08T09:53:47.423838Z",
     "iopub.execute_input": "2024-06-08T09:53:47.424703Z",
     "iopub.status.idle": "2024-06-08T09:54:30.346164Z",
     "shell.execute_reply.started": "2024-06-08T09:53:47.424665Z",
     "shell.execute_reply": "2024-06-08T09:54:30.345087Z"
    },
    "trusted": true
   },
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "text": "2024/06/08 09:54:21 WARNING mlflow.models.model: Model logged without a signature. Signatures will be required for upcoming model registry features as they validate model inputs and denote the expected schema of model outputs. Please visit https://www.mlflow.org/docs/2.13.2/models.html#set-signature-on-logged-model for instructions on setting a model signature on your logged model.\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Uploading artifacts:   0%|          | 0/10 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "55beab32f71d404ea25c427f5ec199cd"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}
